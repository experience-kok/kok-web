import { execSync } from 'child_process';

import { config } from 'dotenv';
import { OpenAI } from 'openai';

config();

// !TODO ê¹ƒì— ì˜¬ë¦´ë•ŒëŠ” next_public ì œê±°
const openai = new OpenAI({ apiKey: process.env.NEXT_PUBLIC_OPENAI_API_KEY });

/** ë³€ê²½ëœ íŒŒì¼ ëª©ë¡ì„ ê°€ì ¸ì˜´ */
function getChangedFiles() {
  const output = execSync('git diff --name-only origin/develop...HEAD').toString();
  console.log(output.split('\n').filter(Boolean));
  return output.split('\n').filter(Boolean);
}

/** íŠ¹ì • íŒŒì¼ì˜ diff ë‚´ìš© ì¶”ì¶œ */
function getFileDiff(file) {
  try {
    return execSync(`git diff develop -- ${file}`).toString();
  } catch (err) {
    console.error(`âŒ ${file} diff ì—ëŸ¬`, err);
    return '';
  }
}

/** GPTì—ê²Œ ë¦¬ë·° ìš”ì²­ */
async function reviewCode(filename, diff) {
  const prompt = `ì•„ë˜ëŠ” ${filename} íŒŒì¼ì˜ ì½”ë“œ ë³€ê²½ ë‚´ìš©ì…ë‹ˆë‹¤. ì´ ë³€ê²½ì‚¬í•­ì— ëŒ€í•´ ì½”ë“œ ë¦¬ë·°ë¥¼ í•´ì£¼ì„¸ìš”:\n\n${diff}`;
  const chat = await openai.chat.completions.create({
    model: 'gpt-3.5-turbo',
    messages: [
      { role: 'system', content: 'ë‹¹ì‹ ì€ ê²½í—˜ ë§ì€ ì½”ë“œ ë¦¬ë·°ì–´ì…ë‹ˆë‹¤.' },
      { role: 'user', content: prompt },
    ],
    max_tokens: 800,
  });

  return chat.choices[0].message.content;
}

(async () => {
  const files = getChangedFiles();
  if (files.length === 0) {
    console.log('ğŸ” ë³€ê²½ëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.');
    return;
  }

  for (const file of files) {
    const diff = getFileDiff(file);
    console.log(diff);

    // if (diff.length > 4000) {
    //   console.log(`âš ï¸ ${file}ì˜ ë³€ê²½ ë‚´ìš©ì´ ë„ˆë¬´ ê¹ë‹ˆë‹¤. ì¼ë¶€ë§Œ ë¶„ì„í•©ë‹ˆë‹¤.`);
    // }

    // const trimmedDiff = diff.slice(0, 4000); // ì•ˆì „í•˜ê²Œ ìë¥´ê¸°

    // console.log(`\nğŸ“„ [${file}] ì½”ë“œ ë¦¬ë·° ìš”ì²­ ì¤‘...\n`);
    // try {
    //   const review = await reviewCode(file, trimmedDiff);
    //   console.log(`ğŸ¤– ë¦¬ë·° ê²°ê³¼:\n${review}\n`);
    // } catch (e) {
    //   console.error(`âŒ ${file} ë¦¬ë·° ì‹¤íŒ¨:`, e.message);
    // }
  }
})();
